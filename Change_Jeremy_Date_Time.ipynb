{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>type</th>\n",
       "      <th>order ID</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>direction</th>\n",
       "      <th>askprice1</th>\n",
       "      <th>askvol1</th>\n",
       "      <th>bidprice1</th>\n",
       "      <th>bidvol1</th>\n",
       "      <th>...</th>\n",
       "      <th>bidvol4</th>\n",
       "      <th>askprice5</th>\n",
       "      <th>askvol5</th>\n",
       "      <th>bidprice5</th>\n",
       "      <th>bidvol5</th>\n",
       "      <th>mid_price</th>\n",
       "      <th>mid_price_mov</th>\n",
       "      <th>type_direction</th>\n",
       "      <th>buy_vol</th>\n",
       "      <th>sell_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34200.005743</td>\n",
       "      <td>4</td>\n",
       "      <td>15835012</td>\n",
       "      <td>34</td>\n",
       "      <td>275200</td>\n",
       "      <td>-1</td>\n",
       "      <td>275200</td>\n",
       "      <td>66</td>\n",
       "      <td>275100</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>661</td>\n",
       "      <td>275700</td>\n",
       "      <td>100</td>\n",
       "      <td>274700</td>\n",
       "      <td>300</td>\n",
       "      <td>275150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34200.006241</td>\n",
       "      <td>1</td>\n",
       "      <td>16114545</td>\n",
       "      <td>100</td>\n",
       "      <td>275200</td>\n",
       "      <td>-1</td>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>661</td>\n",
       "      <td>275700</td>\n",
       "      <td>100</td>\n",
       "      <td>274700</td>\n",
       "      <td>300</td>\n",
       "      <td>275150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34200.006462</td>\n",
       "      <td>1</td>\n",
       "      <td>16114695</td>\n",
       "      <td>100</td>\n",
       "      <td>275500</td>\n",
       "      <td>-1</td>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>661</td>\n",
       "      <td>275600</td>\n",
       "      <td>100</td>\n",
       "      <td>274700</td>\n",
       "      <td>300</td>\n",
       "      <td>275150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34200.048864</td>\n",
       "      <td>3</td>\n",
       "      <td>16063194</td>\n",
       "      <td>100</td>\n",
       "      <td>275000</td>\n",
       "      <td>1</td>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>300</td>\n",
       "      <td>275600</td>\n",
       "      <td>100</td>\n",
       "      <td>274600</td>\n",
       "      <td>700</td>\n",
       "      <td>275150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34200.048883</td>\n",
       "      <td>3</td>\n",
       "      <td>15833239</td>\n",
       "      <td>100</td>\n",
       "      <td>275100</td>\n",
       "      <td>1</td>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>300</td>\n",
       "      <td>275600</td>\n",
       "      <td>100</td>\n",
       "      <td>274600</td>\n",
       "      <td>700</td>\n",
       "      <td>275150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time  type  order ID  size   price  direction  askprice1  askvol1  \\\n",
       "0  34200.005743     4  15835012    34  275200         -1     275200       66   \n",
       "1  34200.006241     1  16114545   100  275200         -1     275200      166   \n",
       "2  34200.006462     1  16114695   100  275500         -1     275200      166   \n",
       "3  34200.048864     3  16063194   100  275000          1     275200      166   \n",
       "4  34200.048883     3  15833239   100  275100          1     275200      166   \n",
       "\n",
       "   bidprice1  bidvol1    ...     bidvol4  askprice5  askvol5  bidprice5  \\\n",
       "0     275100      400    ...         661     275700      100     274700   \n",
       "1     275100      400    ...         661     275700      100     274700   \n",
       "2     275100      400    ...         661     275600      100     274700   \n",
       "3     275100      400    ...         300     275600      100     274600   \n",
       "4     275100      300    ...         300     275600      100     274600   \n",
       "\n",
       "   bidvol5  mid_price  mid_price_mov  type_direction  buy_vol  sell_vol  \n",
       "0      300   275150.0            0.0              -4       34         0  \n",
       "1      300   275150.0            0.0              -1        0         0  \n",
       "2      300   275150.0            0.0              -1        0         0  \n",
       "3      700   275150.0            0.0               3        0         0  \n",
       "4      700   275150.0            0.0               3        0         0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in sign\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#-- import data\n",
    "orderbook_cols = ['{}{}{}'.format(s,t,l) for l in range(1,6) for s in ['ask_','bid_'] for t in ['price_', 'vol_'] ]\n",
    "orderbook_ori = pd.read_csv('INTC_2012-06-21_34200000_57600000_orderbook_5.csv', \\\n",
    "                            header = None, names = orderbook_cols)\n",
    "#orderbook_ori = pd.read_csv('AAPL_2012-06-21_34200000_57600000_orderbook_5.csv', \\\n",
    "#                            header = None, names = orderbook_cols)\n",
    "#orderbook_ori = pd.read_csv('MSFT_2012-06-21_34200000_57600000_orderbook_5.csv', \\\n",
    "#                            header = None, names = orderbook_cols)\n",
    "#orderbook_ori = pd.read_csv('AMZN_2012-06-21_34200000_57600000_orderbook_5.csv', \\\n",
    "#                            header = None, names = orderbook_cols)\n",
    "#orderbook_ori = pd.read_csv('GOOG_2012-06-21_34200000_57600000_orderbook_5.csv', \\\n",
    "#                            header = None, names = orderbook_cols)\n",
    "orderbook = orderbook_ori.copy()\n",
    "orderbook['mid_price'] = (orderbook.iloc[:,0] + orderbook.iloc[:,2]) / 2\n",
    "orderbook['mid_price_mov'] = np.sign(orderbook['mid_price'].shift(-1)-orderbook['mid_price']) # the last one is nan\n",
    "\n",
    "message_cols = ['time', 'type', 'order ID', 'size', 'price', 'direction']\n",
    "message = pd.read_csv('INTC_2012-06-21_34200000_57600000_message_5.csv', \\\n",
    "                          header = None, names = message_cols)\n",
    "#message = pd.read_csv('AAPL_2012-06-21_34200000_57600000_message_5.csv', \\\n",
    "#                          header = None, names = message_cols)\n",
    "#message = pd.read_csv('MSFT_2012-06-21_34200000_57600000_message_5.csv', \\\n",
    "#                          header = None, names = message_cols)\n",
    "#message = pd.read_csv('AMZN_2012-06-21_34200000_57600000_message_5.csv', \\\n",
    "#                          header = None, names = message_cols)\n",
    "#message = pd.read_csv('GOOG_2012-06-21_34200000_57600000_message_5.csv', \\\n",
    "#                          header = None, names = message_cols)\n",
    "total_data = pd.concat([message, orderbook], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in sign\n",
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:274: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n",
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:275: FutureWarning: Currently, 'apply' passes the values as ndarrays to the applied function. In the future, this will change to passing it as Series objects. You need to specify 'raw=True' to keep the current behaviour, and you can pass 'raw=False' to silence this warning\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#-- import data\n",
    "orderbook_cols = ['{}{}{}'.format(s,t,l) for l in range(1,6) for s in ['ask_','bid_'] for t in ['price_', 'vol_'] ]\n",
    "orderbook_ori = pd.read_csv('INTC_2012-06-21_34200000_57600000_orderbook_5.csv', \\\n",
    "                            header = None, names = orderbook_cols)\n",
    "#orderbook_ori = pd.read_csv('AAPL_2012-06-21_34200000_57600000_orderbook_5.csv', \\\n",
    "#                            header = None, names = orderbook_cols)\n",
    "#orderbook_ori = pd.read_csv('MSFT_2012-06-21_34200000_57600000_orderbook_5.csv', \\\n",
    "#                            header = None, names = orderbook_cols)\n",
    "#orderbook_ori = pd.read_csv('AMZN_2012-06-21_34200000_57600000_orderbook_5.csv', \\\n",
    "#                            header = None, names = orderbook_cols)\n",
    "#orderbook_ori = pd.read_csv('GOOG_2012-06-21_34200000_57600000_orderbook_5.csv', \\\n",
    "#                            header = None, names = orderbook_cols)\n",
    "orderbook = orderbook_ori.copy()\n",
    "orderbook['mid_price'] = (orderbook.iloc[:,0] + orderbook.iloc[:,2]) / 2\n",
    "orderbook['mid_price_mov'] = np.sign(orderbook['mid_price'].shift(-1)-orderbook['mid_price']) # the last one is nan\n",
    "\n",
    "message_cols = ['time', 'type', 'order ID', 'size', 'price', 'direction']\n",
    "message = pd.read_csv('INTC_2012-06-21_34200000_57600000_message_5.csv', \\\n",
    "                          header = None, names = message_cols)\n",
    "#message = pd.read_csv('AAPL_2012-06-21_34200000_57600000_message_5.csv', \\\n",
    "#                          header = None, names = message_cols)\n",
    "#message = pd.read_csv('MSFT_2012-06-21_34200000_57600000_message_5.csv', \\\n",
    "#                          header = None, names = message_cols)\n",
    "#message = pd.read_csv('AMZN_2012-06-21_34200000_57600000_message_5.csv', \\\n",
    "#                          header = None, names = message_cols)\n",
    "#message = pd.read_csv('GOOG_2012-06-21_34200000_57600000_message_5.csv', \\\n",
    "#                          header = None, names = message_cols)\n",
    "total_data = pd.concat([message, orderbook], axis = 1)\n",
    "\n",
    "total_data[\"Trade_Price\"]=np.nan\n",
    "total_data.loc[total_data.direction==-1,\"Trade_Price\"] = total_data.loc[total_data.direction==-1,\"bid_price_1\"]\n",
    "total_data.loc[total_data.direction==1,\"Trade_Price\"] = total_data.loc[total_data.direction==-1,\"ask_price_1\"]\n",
    "\n",
    "total_data[\"Trade_Vol\"]=np.nan\n",
    "total_data.loc[total_data.direction==-1,\"Trade_Vol\"] = total_data.loc[total_data.direction==-1,\"bid_vol_1\"]\n",
    "total_data.loc[total_data.direction==1,\"Trade_Vol\"] = total_data.loc[total_data.direction==-1,\"ask_vol_1\"]\n",
    "\n",
    "#all_features = pd.concat([message.time, orderbook_ori], axis = 1)\n",
    "all_features = orderbook_ori.copy()\n",
    "all_features['time'] = message[\"time\"]\n",
    "#all_features['sec']=all_features['time'].split(\".\")[0]\n",
    "#all_features['millsec']=all_features['time'].split(\".\")[0]\n",
    "all_features[\"Trade_Price\"]=total_data[\"Trade_Price\"]\n",
    "#-- new feature 1: order flow (could try different lagged periods)\n",
    "'''\n",
    "order flow = the ratio of the volume of market buy(sell) orders arriving in the prior 50 observations \n",
    "             to the resting volume of ask(bid) limit orders at the top of book\n",
    "This feature is constructed according to the paper.\n",
    "# Since we do not have \"number of order\" data, here just use \"volume of order\" instead.\n",
    "Intuition: an increase in this ratio will more likely deplete the best ask level and the mid-price will up-tick,\n",
    "           and vice-versa for a down-tick.\n",
    "'''\n",
    "total_data['type_direction'] = total_data['type'] * total_data['direction']\n",
    "total_data['buy_vol'] = 0\n",
    "buy_order_index1 = total_data[total_data['type_direction'] == -4].index\n",
    "total_data.loc[buy_order_index1, 'buy_vol'] = total_data['size']\n",
    "# Not include type=5(Execution of a hidden limit order), since its update does not change the limit order book.\n",
    "#buy_order_index2 = total_data[total_data['type_direction'] == -5].index\n",
    "#total_data.loc[buy_order_index2, 'buy_vol'] = total_data['size']\n",
    "total_data['sell_vol'] = 0\n",
    "sell_order_index1 = total_data[total_data['type_direction'] == 4].index\n",
    "total_data.loc[sell_order_index1, 'sell_vol'] = total_data['size']\n",
    "#sell_order_index2 = total_data[total_data['type_direction'] == 5].index\n",
    "#total_data.loc[sell_order_index2, 'sell_vol'] = total_data['size']\n",
    "\n",
    "total_data['order_flow_buy'] = total_data['buy_vol'].rolling(50, min_periods = 1).sum() / total_data['ask_vol_1']\n",
    "total_data['order_flow_sell'] = total_data['sell_vol'].rolling(50, min_periods = 1).sum() / total_data['bid_vol_1']\n",
    "\n",
    "#total_data['order_flow_buy'].fillna(method='ffill', inplace=True)\n",
    "#total_data['order_flow_sell'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "all_features['order_flow_buy'] = total_data['order_flow_buy']\n",
    "all_features['order_flow_sell'] = total_data['order_flow_sell']\n",
    "\n",
    "#-- new feature 2: liquidity imbalance\n",
    "'''\n",
    "liquidity imbalance at level i = ask_vol_i / (ask_vol_i + bid_vol_i)\n",
    "This feature is constructed according to the ppt.\n",
    "'''\n",
    "for i in range(1,6):\n",
    "    total_data['liq_imb_'+str(i)] = total_data['ask_vol_'+str(i)] \\\n",
    "                                  / (total_data['ask_vol_'+str(i)] + total_data['bid_vol_'+str(i)])\n",
    "    \n",
    "#    total_data['liq_imb_'+str(i)].fillna(method='ffill', inplace=True)\n",
    "    all_features['liq_imb_'+str(i)] = total_data['liq_imb_'+str(i)]\n",
    "\n",
    "#-- new feature 3: actual spread\n",
    "'''\n",
    "actual spread = ask_price_1 - bid_price_1\n",
    "This feature is constructed according to:\n",
    "1. Michael Kearns..._Machine Learning for Market Microstructure...P7\n",
    "2. Irene Aldridge_High-frequency trading...(2013) P190:\n",
    "   First suggested by Bagehot (1971) and later developed by numerous researchers, the bid-ask spread \n",
    "   reflects the expectations of market movements by the market maker using asymmetric information.\n",
    "'''\n",
    "total_data['actual_spread'] = total_data['ask_price_1'] - total_data['bid_price_1']\n",
    "\n",
    "#total_data['actual_spread'].fillna(method='ffill', inplace=True)\n",
    "all_features['actual_spread'] = total_data['actual_spread']\n",
    "\n",
    "#-- new feature 4: actual market imbalance (could try different lagged periods)\n",
    "'''\n",
    "actual market imbalance = the volume of market buy orders arriving in the prior 50 observations\n",
    "                        - the volume of market sell orders arriving in the prior 50 observations\n",
    "This feature is derived from paper: Michael Kearns..._Machine Learning for Market Microstructure...P8\n",
    "'''\n",
    "total_data['actual_mkt_imb'] = total_data['buy_vol'].rolling(50, min_periods = 1).sum()\\\n",
    "                             - total_data['sell_vol'].rolling(50, min_periods = 1).sum()\n",
    "\n",
    "#total_data['actual_mkt_imb'].fillna(method='ffill', inplace=True)\n",
    "all_features['actual_mkt_imb'] = total_data['actual_mkt_imb']\n",
    "\n",
    "#-- new feature 5: relative market imbalance (could try different lagged periods)\n",
    "'''\n",
    "relative market imbalance = actual market imbalance / actual spread\n",
    "This feature is derived from paper: Michael Kearns..._Machine Learning for Market Microstructure...P8\n",
    "Intuition: a small actual spread combined with a strongly positive actual market imbalance\n",
    "           would indicate buying pressure.\n",
    "'''\n",
    "total_data['relative_mkt_imb'] = total_data['actual_mkt_imb'] / total_data['actual_spread']\n",
    "\n",
    "#total_data['relative_mkt_imb'].fillna(method='ffill', inplace=True)\n",
    "all_features['relative_mkt_imb'] = total_data['relative_mkt_imb']\n",
    "\n",
    "#-- new feature 6: relative_mid_price_trend\n",
    "'''\n",
    "First, construct a variation on mid-price where the average of the bid and ask prices is weighted \n",
    "according to their inverse volume. Then, divide this variation by common mid price.\n",
    "This feature is derived from paper: Michael Kearns..._Machine Learning for Market Microstructure...P10\n",
    "Intuition: a larger relative_mid_price_trend would more likely lead to a up-tick.\n",
    "'''\n",
    "\n",
    "total_data['mid_price_inv_vol_weighted'] = (total_data['ask_price_1'] / total_data['ask_vol_1'] \\\n",
    "                                         + total_data['bid_price_1'] / total_data['bid_vol_1'])\\\n",
    "                                         / (1 / total_data['ask_vol_1'] + 1 / total_data['bid_vol_1'])\n",
    "total_data['relative_mid_price_trend'] = total_data['mid_price_inv_vol_weighted'] / total_data['mid_price']\n",
    "\n",
    "#total_data['relative_mid_price_trend'].fillna(method='ffill', inplace=True)\n",
    "all_features['relative_mid_price_trend'] = total_data['relative_mid_price_trend']\n",
    "\n",
    "#-- new feature 7: relative spread\n",
    "'''\n",
    "relative spread =  (actual spread / mid price) * 10000\n",
    "This feature is derived from paper: Angelo Ranaldo..._Order aggressiveness in limit order book markets...P4\n",
    "'''\n",
    "total_data['relative_spread'] = (total_data['actual_spread'] / total_data['mid_price']) * 1000\n",
    "\n",
    "#total_data['relative_spread'].fillna(method='ffill', inplace=True)\n",
    "all_features['relative_spread'] = total_data['relative_spread']\n",
    "\n",
    "#-- new feature 8: volatility (could try different lagged periods)\n",
    "'''\n",
    "The volatility is the standard deviation of the last 50 midquote returns then divided by 100\n",
    "This feature is derived from paper: Angelo Ranaldo..._Order aggressiveness in limit order book markets...P4\n",
    "'''\n",
    "total_data['mid_price_return'] = total_data['mid_price'].shift(-1) - total_data['mid_price']\n",
    "total_data['volatility_look_ahead'] = (total_data['mid_price_return'].rolling(50, min_periods = 1).std()) / 100\n",
    "total_data['volatility'] = total_data['volatility_look_ahead'].shift(1)\n",
    "\n",
    "#total_data['volatility'].fillna(method='ffill', inplace=True)\n",
    "all_features['volatility'] = total_data['volatility']\n",
    "\n",
    "#-- new feature 9: limit order aggressiveness (could try different lagged periods)\n",
    "'''\n",
    "bid(ask) limit order aggressiveness = the ratio of bid(ask) limit orders submitted at no lower(higher) than \n",
    "                                                   the best bid(ask) prices in the prior 50 observations\n",
    "                                                to total bid(ask) limit orders submitted in prior 50 observations\n",
    "This feature is derived from book: Irene Aldridge_High-frequency trading...(2013) P186\n",
    "Intuition: The higher the ratio, the more aggressive is the trader in his bid(ask) to capture the best \n",
    "           available price and the more likely the trader is to believe that the price is about to \n",
    "           move away from the mid price.\n",
    "'''\n",
    "# ask limit order aggressiveness\n",
    "if_ask_sbmt_agr_mid1 = (total_data['type_direction'] == -1)\n",
    "if_ask_sbmt_agr_mid2 = (total_data['price'] <= total_data['ask_price_1'].shift(1))\n",
    "if_ask_sbmt_agr = (if_ask_sbmt_agr_mid1 & if_ask_sbmt_agr_mid2)\n",
    "\n",
    "total_data['if_ask_sbmt_agr'] = if_ask_sbmt_agr\n",
    "if_ask_sbmt_agr_index = total_data[total_data['if_ask_sbmt_agr'] == True].index\n",
    "total_data['ask_vol_sbmt_agr'] = 0\n",
    "total_data.loc[if_ask_sbmt_agr_index, 'ask_vol_sbmt_agr'] = total_data['size']\n",
    "\n",
    "if_ask_sbmt_index = total_data[total_data['type_direction'] == -1].index\n",
    "total_data['ask_vol_sbmt'] = 0\n",
    "total_data.loc[if_ask_sbmt_index, 'ask_vol_sbmt'] = total_data['size']\n",
    "\n",
    "total_data['lo_agr_ask'] = total_data['ask_vol_sbmt_agr'].rolling(50, min_periods = 1).sum()\\\n",
    "                         / total_data['ask_vol_sbmt'].rolling(50, min_periods = 1).sum()\n",
    "\n",
    "#total_data['lo_agr_ask'].fillna(method='ffill', inplace=True)\n",
    "all_features['lo_agr_ask'] = total_data['lo_agr_ask']\n",
    "\n",
    "# bid limit order aggressiveness\n",
    "if_bid_sbmt_agr_mid1 = (total_data['type_direction'] == 1)\n",
    "if_bid_sbmt_agr_mid2 = (total_data['price'] >= total_data['bid_price_1'].shift(1))\n",
    "if_bid_sbmt_agr = (if_bid_sbmt_agr_mid1 & if_bid_sbmt_agr_mid2)\n",
    "\n",
    "total_data['if_bid_sbmt_agr'] = if_bid_sbmt_agr\n",
    "if_bid_sbmt_agr_index = total_data[total_data['if_bid_sbmt_agr'] == True].index\n",
    "total_data['bid_vol_sbmt_agr'] = 0\n",
    "total_data.loc[if_bid_sbmt_agr_index, 'bid_vol_sbmt_agr'] = total_data['size']\n",
    "\n",
    "if_bid_sbmt_index = total_data[total_data['type_direction'] == 1].index\n",
    "total_data['bid_vol_sbmt'] = 0\n",
    "total_data.loc[if_bid_sbmt_index, 'bid_vol_sbmt'] = total_data['size']\n",
    "\n",
    "total_data['lo_agr_bid'] = total_data['bid_vol_sbmt_agr'].rolling(50, min_periods = 1).sum()\\\n",
    "                         / total_data['bid_vol_sbmt'].rolling(50, min_periods = 1).sum()\n",
    "\n",
    "#total_data['lo_agr_bid'].fillna(method='ffill', inplace=True)\n",
    "all_features['lo_agr_bid'] = total_data['lo_agr_bid']\n",
    "\n",
    "#-- new feature 10: effective spread\n",
    "'''\n",
    "The effective spread is computed as difference between the latest trade price and midprice \n",
    "                                    divided by midprice, then times 1000.\n",
    "This feature is derived from book: Irene Aldridge_High-frequency trading...(2013) P191\n",
    "Intuition: The effective spread measures how far, in percentage terms, the latest realized price \n",
    "           fell away from the simple mid price.\n",
    "'''\n",
    "if_lastest_trade_index = total_data[total_data['type'] == 4].index\n",
    "if_not_lastest_trade_index = total_data[total_data['type'] != 4].index\n",
    "total_data['lastest_trade_price'] = 0\n",
    "total_data.loc[if_lastest_trade_index,'lastest_trade_price'] = total_data['price']\n",
    "total_data.loc[if_not_lastest_trade_index,'lastest_trade_price'] = np.nan\n",
    "total_data['lastest_trade_price'].fillna(method='ffill',inplace = True)\n",
    "\n",
    "total_data['effective_spread'] = (total_data['lastest_trade_price'] / total_data['mid_price'] - 1) * 1000\n",
    "\n",
    "#total_data['effective_spread'].fillna(method='ffill', inplace=True)\n",
    "all_features['effective_spread'] = total_data['effective_spread']\n",
    "\n",
    "#-- new feature 11: ILLIQ\n",
    "\"\"\"\n",
    "The illiquidity is computed as the ratio of absolute stock return to its dollar volume.\n",
    "This feature is derived from Amihud (2002)\n",
    "\"\"\"\n",
    "\n",
    "total_data['mid_price_ret'] = np.log(total_data['mid_price']) - np.log(total_data['mid_price'].shift(1))  \n",
    "total_data['ret_over_volume'] = abs(total_data['mid_price_ret']) / (total_data['ask_vol_1'] + total_data['bid_vol_1'])\n",
    "total_data['ILLIQ'] = total_data['ret_over_volume'].rolling(50, min_periods = 1).sum()\n",
    "\n",
    "all_features['ILLIQ'] = total_data['ILLIQ']\n",
    "\n",
    "#-- new feature 12: relative volume\n",
    "\"\"\"\n",
    "Relative volume is computed as the ratio of current volume to the historical average volume\n",
    "\"\"\"\n",
    "\n",
    "for i in range(1,6):\n",
    "    \n",
    "    total_data['rel_ask_vol_'+str(i)] = total_data['ask_vol_'+str(i)] / total_data['ask_vol_'+str(i)].rolling(50, min_periods = 1).mean()\n",
    "    total_data['rel_bid_vol_'+str(i)] = total_data['bid_vol_'+str(i)] / total_data['bid_vol_'+str(i)].rolling(50, min_periods = 1).mean()\n",
    " \n",
    "    all_features['rel_bid_vol_'+str(i)] = total_data['rel_bid_vol_'+str(i)]\n",
    "    all_features['rel_ask_vol_'+str(i)] = total_data['rel_ask_vol_'+str(i)]\n",
    "\n",
    "#-- new feature 13: volume depth\n",
    "    \n",
    "\"\"\"\n",
    "Volume depth is computed as the ratio of best volume to the sum of all depth volume\n",
    "\"\"\"\n",
    "total_data['depth_ask_vol'] = total_data['ask_vol_1'] / (total_data['ask_vol_1'] + total_data['ask_vol_2'] + total_data['ask_vol_3']\\\n",
    "          + total_data['ask_vol_4'] + total_data['ask_vol_5'])\n",
    "total_data['depth_bid_vol'] = total_data['bid_vol_1'] / (total_data['bid_vol_1'] + total_data['bid_vol_2'] + total_data['bid_vol_3']\\\n",
    "          + total_data['bid_vol_4'] + total_data['bid_vol_5'])\n",
    " \n",
    "all_features['depth_ask_vol'] = total_data['depth_ask_vol']\n",
    "all_features['depth_bid_vol'] = total_data['depth_bid_vol']\n",
    "\n",
    "\n",
    "#-- new feature 14: volume rank\n",
    "\"\"\"\n",
    "volume rank is computed as the rank of current volume with respect to the previous 50days volume\n",
    "\"\"\"\n",
    "\n",
    "rollrank = lambda x: (x.argsort().argsort()[-1]+1.0)/len(x)\n",
    "\n",
    "for i in range(1,6):\n",
    "    \n",
    "    total_data['rank_ask_vol_'+str(i)] = total_data['ask_vol_'+str(i)].rolling(50, min_periods = 1).apply(rollrank)\n",
    "    total_data['rank_bid_vol_'+str(i)] = total_data['bid_vol_'+str(i)].rolling(50, min_periods = 1).apply(rollrank)\n",
    "    \n",
    "    total_data['rank_ask_vol_'+str(i)] = total_data['rank_ask_vol_'+str(i)].fillna(method='ffill',axis=0)\n",
    "    total_data['rank_bid_vol_'+str(i)] = total_data['rank_bid_vol_'+str(i)].fillna(method='ffill',axis=0)\n",
    "    total_data['rank_ask_vol_'+str(i)] = np.clip(total_data['rank_ask_vol_'+str(i)], 0, 1)\n",
    "    total_data['rank_bid_vol_'+str(i)] = np.clip(total_data['rank_bid_vol_'+str(i)], 0, 1)    \n",
    " \n",
    "    all_features['rank_bid_vol_'+str(i)] = total_data['rank_bid_vol_'+str(i)]\n",
    "    all_features['rank_ask_vol_'+str(i)] = total_data['rank_ask_vol_'+str(i)]\n",
    "\n",
    "#-- new feature 15: ask bid volume correlation\n",
    "\"\"\"\n",
    "ask bid volume correlation is comupted as 50 days time series correlation between ask and bid volume for each level\n",
    "\"\"\"\n",
    "\n",
    "for i in range(1,6):  \n",
    "    total_data['corr_vol_'+str(i)] = total_data['ask_vol_'+str(i)].rolling(50, min_periods = 1).corr(total_data['bid_vol_'+str(i)])\n",
    "    \n",
    "    total_data['corr_vol_'+str(i)] = total_data['corr_vol_'+str(i)].fillna(method='ffill',axis=0)\n",
    "    total_data['corr_vol_'+str(i)] = np.clip(total_data['corr_vol_'+str(i)], -1, 1)\n",
    "    \n",
    "    all_features['corr_vol_'+str(i)] = total_data['corr_vol_'+str(i)]\n",
    "\n",
    "#--\n",
    "all_features['label'] = total_data['mid_price_mov']\n",
    "\n",
    "all_features = all_features.dropna()\n",
    "\n",
    "all_features['label'] = all_features['label'].astype(int)\n",
    "\n",
    "#-- export data\n",
    "new_features_resultpath = '/Users/meihuaren/personal/OR_2018fall/Courses/E4720 Deep Learning/project_coding/Team E_code/'\n",
    "#filename1 = new_features_resultpath + 'total_data.csv'\n",
    "#total_data.to_csv(filename1)\n",
    "\n",
    "filename2 = new_features_resultpath + 'all_features_new.csv'\n",
    "#filename2 = new_features_resultpath + 'all_features_new_aapl.csv'\n",
    "#ilename2 = new_features_resultpath + 'all_features_new_msft.csv'\n",
    "#filename2 = new_features_resultpath + 'all_features_new_amzn.csv'\n",
    "#filename2 = new_features_resultpath + 'all_features_new_goog.csv'\n",
    "#all_features.to_csv(filename2,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features.to_csv('all_features_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     34200.049011\n",
       "7     34200.049078\n",
       "8     34200.049110\n",
       "9     34200.049301\n",
       "10    34200.211338\n",
       "Name: time, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTradingDay(filename = 'all_features_new.csv'):\n",
    "    #Unlock in final testing###\n",
    "    file_path = './data/' + filename\n",
    "    \n",
    "    tick_df = pd.read_csv(file_path, sep=',')\n",
    "    #tick_df.time.str.split(\".\")\n",
    "    tick_df.index = pd.to_datetime(tick_df.time,unit='s',origin=\"2012-06-21\")\n",
    "    \n",
    "    # Only take bid prices from exchange 'Q'. Other bid prices seem to be unreliable\n",
    "    #to_be_filtered = (tick_df.Exchange == 'Q').values + (np.isfinite(tick_df['Trade Price'])).values\n",
    "\n",
    "    #tick_df = tick_df[to_be_filtered]\n",
    "\n",
    "    #tick_df['Bid_Price'] = tick_df['Bid_Price'].fillna(method = 'ffill')\n",
    "\n",
    "    # trade dataframe\n",
    "    df_trading_day = tick_df\n",
    "\n",
    "    # standardize the bid_prices\n",
    "    mu_bid = df_trading_day['Bid_price'].mean()\n",
    "    std_bid = df_trading_day['Bid_price'].std()\n",
    "    #df_trades['Bid_Price'] = (df_trades['Bid_Price'] - mu_bid)/std_bid\n",
    "    # remove bid prices outliers\n",
    "    #df_trades = df_trades[np.abs(df_trades['Bid_Price'] - df_trades['Bid_Price'].rolling(25).mean()) <= (2 * df_trades['Bid_Price'].std())]\n",
    "\n",
    "    # clean the trades\n",
    "    #df_trades = df_trades[np.abs(df_trades['Trade Price'] - df_trades['Trade Price'].rolling(25).mean()) <= (3 * df_trades['Trade Price'].rolling(25).std())]\n",
    "    #df_trades['Trade Price'] = (df_trades['Trade Price'] - mu_bid)/std_bid\n",
    "    #df_trading_day = df_trades['01-17-18 09:30:00': '01-17-18 15:55:00']\n",
    "    # drop unnecessary columns\n",
    "    #df_trading_day = df_trading_day.drop(['Offer_Price', 'Offer_Size', 'Quote_Condition', 'Bid_Size', 'Exchange', 'Symbol', 'Sale Condition'], axis = 1)\n",
    "    #print(df_trading_day.columns)\n",
    "\n",
    "    time = df_trading_day.index - pd.Timedelta(hours = 9, minutes = 30)\n",
    "    time_in_minutes = time.hour*60 + time.minute\n",
    "    time_in_minutes = time_in_minutes.values\n",
    "    mu_time = time_in_minutes.mean()\n",
    "    std_time = time_in_minutes.std()\n",
    "    df_trading_day['time_in_minutes'] = time_in_minutes\n",
    "\n",
    "    #momentum = (df_trading_day['Trade Price'].pct_change() * df_trading_day['Trade Volume']).rolling(window = 10).sum().fillna(0)\n",
    "    #df_trading_day['momentum'] = momentum\n",
    "\n",
    "    \"\"\" print(\"\")\n",
    "    print(\"There are \" + str(df_trading_day.shape[0]) + \" number of ticks\")\n",
    "    print(\"\")\n",
    "    # a total of 210360 ticks\n",
    "    \"\"\"\n",
    "    upperBound = (df_trading_day.index >= '01-17-18 15:54:00').argmax()\n",
    "\n",
    "    return df_trading_day, upperBound, mu_bid, mu_time, std_bid, std_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trading_day, upperBound, mu_bid, mu_time, std_bid, std_time = genTradingDay(filename = 'all_features_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>ask_vol_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "      <th>bid_vol_1</th>\n",
       "      <th>ask_price_2</th>\n",
       "      <th>ask_vol_2</th>\n",
       "      <th>bid_price_2</th>\n",
       "      <th>bid_vol_2</th>\n",
       "      <th>ask_price_3</th>\n",
       "      <th>ask_vol_3</th>\n",
       "      <th>...</th>\n",
       "      <th>rank_ask_vol_4</th>\n",
       "      <th>rank_bid_vol_5</th>\n",
       "      <th>rank_ask_vol_5</th>\n",
       "      <th>corr_vol_1</th>\n",
       "      <th>corr_vol_2</th>\n",
       "      <th>corr_vol_3</th>\n",
       "      <th>corr_vol_4</th>\n",
       "      <th>corr_vol_5</th>\n",
       "      <th>label</th>\n",
       "      <th>time_in_minutes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-06-21 09:30:00.049011</th>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>300</td>\n",
       "      <td>275300</td>\n",
       "      <td>1000</td>\n",
       "      <td>275000</td>\n",
       "      <td>100</td>\n",
       "      <td>275400</td>\n",
       "      <td>373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.353553</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 09:30:00.049078</th>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>300</td>\n",
       "      <td>275300</td>\n",
       "      <td>1000</td>\n",
       "      <td>275000</td>\n",
       "      <td>100</td>\n",
       "      <td>275400</td>\n",
       "      <td>373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.377964</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 09:30:00.049110</th>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>300</td>\n",
       "      <td>275300</td>\n",
       "      <td>1000</td>\n",
       "      <td>275000</td>\n",
       "      <td>100</td>\n",
       "      <td>275400</td>\n",
       "      <td>373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.395285</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 09:30:00.049300</th>\n",
       "      <td>275200</td>\n",
       "      <td>166</td>\n",
       "      <td>275100</td>\n",
       "      <td>300</td>\n",
       "      <td>275300</td>\n",
       "      <td>1000</td>\n",
       "      <td>275000</td>\n",
       "      <td>300</td>\n",
       "      <td>275400</td>\n",
       "      <td>373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.408248</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-21 09:30:00.211338</th>\n",
       "      <td>275200</td>\n",
       "      <td>100</td>\n",
       "      <td>275100</td>\n",
       "      <td>300</td>\n",
       "      <td>275300</td>\n",
       "      <td>1000</td>\n",
       "      <td>275000</td>\n",
       "      <td>300</td>\n",
       "      <td>275400</td>\n",
       "      <td>373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.228210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ask_price_1  ask_vol_1  bid_price_1  bid_vol_1  \\\n",
       "time                                                                         \n",
       "2012-06-21 09:30:00.049011       275200        166       275100        300   \n",
       "2012-06-21 09:30:00.049078       275200        166       275100        300   \n",
       "2012-06-21 09:30:00.049110       275200        166       275100        300   \n",
       "2012-06-21 09:30:00.049300       275200        166       275100        300   \n",
       "2012-06-21 09:30:00.211338       275200        100       275100        300   \n",
       "\n",
       "                            ask_price_2  ask_vol_2  bid_price_2  bid_vol_2  \\\n",
       "time                                                                         \n",
       "2012-06-21 09:30:00.049011       275300       1000       275000        100   \n",
       "2012-06-21 09:30:00.049078       275300       1000       275000        100   \n",
       "2012-06-21 09:30:00.049110       275300       1000       275000        100   \n",
       "2012-06-21 09:30:00.049300       275300       1000       275000        300   \n",
       "2012-06-21 09:30:00.211338       275300       1000       275000        300   \n",
       "\n",
       "                            ask_price_3  ask_vol_3       ...         \\\n",
       "time                                                     ...          \n",
       "2012-06-21 09:30:00.049011       275400        373       ...          \n",
       "2012-06-21 09:30:00.049078       275400        373       ...          \n",
       "2012-06-21 09:30:00.049110       275400        373       ...          \n",
       "2012-06-21 09:30:00.049300       275400        373       ...          \n",
       "2012-06-21 09:30:00.211338       275400        373       ...          \n",
       "\n",
       "                            rank_ask_vol_4  rank_bid_vol_5  rank_ask_vol_5  \\\n",
       "time                                                                         \n",
       "2012-06-21 09:30:00.049011             1.0        0.714286             1.0   \n",
       "2012-06-21 09:30:00.049078             1.0        0.750000             1.0   \n",
       "2012-06-21 09:30:00.049110             1.0        1.000000             1.0   \n",
       "2012-06-21 09:30:00.049300             1.0        1.000000             1.0   \n",
       "2012-06-21 09:30:00.211338             1.0        1.000000             1.0   \n",
       "\n",
       "                            corr_vol_1  corr_vol_2  corr_vol_3  corr_vol_4  \\\n",
       "time                                                                         \n",
       "2012-06-21 09:30:00.049011   -0.353553        -1.0        -1.0        -1.0   \n",
       "2012-06-21 09:30:00.049078   -0.377964        -1.0        -1.0        -1.0   \n",
       "2012-06-21 09:30:00.049110   -0.395285        -1.0        -1.0        -1.0   \n",
       "2012-06-21 09:30:00.049300   -0.408248        -1.0        -1.0        -1.0   \n",
       "2012-06-21 09:30:00.211338   -0.228210         1.0        -1.0         1.0   \n",
       "\n",
       "                            corr_vol_5  label  time_in_minutes  \n",
       "time                                                            \n",
       "2012-06-21 09:30:00.049011         1.0      0                0  \n",
       "2012-06-21 09:30:00.049078         1.0      0                0  \n",
       "2012-06-21 09:30:00.049110         1.0      0                0  \n",
       "2012-06-21 09:30:00.049300         1.0      0                0  \n",
       "2012-06-21 09:30:00.211338         1.0      1                0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trading_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
